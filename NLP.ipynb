{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# import warnings filter\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the scikit-learn data set:\n",
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract information from the data's dictionary format \n",
    "\n",
    "categories = ['alt.atheism',\n",
    "'talk.religion.misc',\n",
    "'comp.graphics',\n",
    "'sci.space']\n",
    "\n",
    "# Set training data\n",
    "data_train = fetch_20newsgroups(subset='train', categories=categories,\n",
    "                                shuffle=True, random_state=42,\n",
    "                                remove=('headers', 'footers', 'quotes'))\n",
    "# Set testing data\n",
    "data_test = fetch_20newsgroups(subset='test', categories=categories,\n",
    "                               shuffle=True, random_state=42,\n",
    "                               remove=('headers', 'footers', 'quotes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.Bunch"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2034"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_train.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi,\n",
      "\n",
      "I've noticed that if you only save a model (with all your mapping planes\n",
      "positioned carefully) to a .3DS file that when you reload it after restarting\n",
      "3DS, they are given a default position and orientation.  But if you save\n",
      "to a .PRJ file their positions/orientation are preserved.  Does anyone\n",
      "know why this information is not stored in the .3DS file?  Nothing is\n",
      "explicitly said in the manual about saving texture rules in the .PRJ file. \n",
      "I'd like to be able to read the texture rule information, does anyone have \n",
      "the format for the .PRJ file?\n",
      "\n",
      "Is the .CEL file format available from somewhere?\n",
      "\n",
      "Rych\n"
     ]
    }
   ],
   "source": [
    "print(data_train.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a bag-of-words model\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvect = CountVectorizer()\n",
    "X_train = data_train.data\n",
    "cvect.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hi': 12171,\n",
       " 've': 25588,\n",
       " 'noticed': 17138,\n",
       " 'that': 24080,\n",
       " 'if': 12693,\n",
       " 'you': 26764,\n",
       " 'only': 17493,\n",
       " 'save': 21405,\n",
       " 'model': 16239,\n",
       " 'with': 26405,\n",
       " 'all': 3042,\n",
       " 'your': 26768,\n",
       " 'mapping': 15466,\n",
       " 'planes': 18636,\n",
       " 'positioned': 18898,\n",
       " 'carefully': 5443,\n",
       " 'to': 24380,\n",
       " '3ds': 1152,\n",
       " 'file': 10376,\n",
       " 'when': 26235,\n",
       " 'reload': 20439,\n",
       " 'it': 13712,\n",
       " 'after': 2853,\n",
       " 'restarting': 20713,\n",
       " 'they': 24155,\n",
       " 'are': 3607,\n",
       " 'given': 11310,\n",
       " 'default': 7761,\n",
       " 'position': 18896,\n",
       " 'and': 3254,\n",
       " 'orientation': 17648,\n",
       " 'but': 5220,\n",
       " 'prj': 19263,\n",
       " 'their': 24092,\n",
       " 'positions': 18901,\n",
       " 'preserved': 19146,\n",
       " 'does': 8620,\n",
       " 'anyone': 3397,\n",
       " 'know': 14291,\n",
       " 'why': 26289,\n",
       " 'this': 24191,\n",
       " 'information': 13153,\n",
       " 'is': 13651,\n",
       " 'not': 17121,\n",
       " 'stored': 23103,\n",
       " 'in': 12920,\n",
       " 'the': 24082,\n",
       " 'nothing': 17134,\n",
       " 'explicitly': 9935,\n",
       " 'said': 21284,\n",
       " 'manual': 15444,\n",
       " 'about': 2427,\n",
       " 'saving': 21409,\n",
       " 'texture': 24057,\n",
       " 'rules': 21177,\n",
       " 'like': 14847,\n",
       " 'be': 4326,\n",
       " 'able': 2408,\n",
       " 'read': 20041,\n",
       " 'rule': 21173,\n",
       " 'have': 11962,\n",
       " 'format': 10701,\n",
       " 'for': 10651,\n",
       " 'cel': 5604,\n",
       " 'available': 4030,\n",
       " 'from': 10874,\n",
       " 'somewhere': 22504,\n",
       " 'rych': 21225,\n",
       " 'seems': 21696,\n",
       " 'barring': 4252,\n",
       " 'evidence': 9744,\n",
       " 'contrary': 6887,\n",
       " 'koresh': 14330,\n",
       " 'was': 26066,\n",
       " 'simply': 22163,\n",
       " 'another': 3341,\n",
       " 'deranged': 7972,\n",
       " 'fanatic': 10165,\n",
       " 'who': 26270,\n",
       " 'thought': 24212,\n",
       " 'neccessary': 16783,\n",
       " 'take': 23758,\n",
       " 'whole': 26273,\n",
       " 'bunch': 5156,\n",
       " 'of': 17380,\n",
       " 'folks': 10614,\n",
       " 'him': 12217,\n",
       " 'children': 5844,\n",
       " 'satisfy': 21385,\n",
       " 'his': 12242,\n",
       " 'delusional': 7871,\n",
       " 'mania': 15409,\n",
       " 'jim': 13869,\n",
       " 'jones': 13922,\n",
       " 'circa': 5944,\n",
       " '1993': 581,\n",
       " 'nope': 17086,\n",
       " 'fruitcakes': 10888,\n",
       " 'been': 4370,\n",
       " 'demonstrating': 7900,\n",
       " 'such': 23347,\n",
       " 'evil': 9749,\n",
       " 'corruption': 7045,\n",
       " 'centuries': 5646,\n",
       " 'article': 3698,\n",
       " '1993apr19': 585,\n",
       " '020359': 55,\n",
       " '26996': 859,\n",
       " 'sq': 22809,\n",
       " 'com': 6300,\n",
       " 'msb': 16494,\n",
       " 'mark': 15500,\n",
       " 'brader': 4935,\n",
       " 'mb': 15653,\n",
       " 'so': 22412,\n",
       " '1970': 551,\n",
       " 'figure': 10372,\n",
       " 'unlikely': 25202,\n",
       " 'actually': 2629,\n",
       " 'anything': 3398,\n",
       " 'perijove': 18281,\n",
       " 'jg': 13858,\n",
       " 'sorry': 22528,\n",
       " '_perijoves_': 2271,\n",
       " 'used': 25379,\n",
       " 'talking': 23775,\n",
       " 'language': 14472,\n",
       " 'couldn': 7074,\n",
       " 'we': 26113,\n",
       " 'just': 14041,\n",
       " 'say': 21418,\n",
       " 'periapsis': 18274,\n",
       " 'or': 17590,\n",
       " 'apoapsis': 3435,\n",
       " 'request': 20621,\n",
       " 'those': 24208,\n",
       " 'would': 26521,\n",
       " 'see': 21681,\n",
       " 'charley': 5769,\n",
       " 'wingate': 26357,\n",
       " 'respond': 20699,\n",
       " 'challenges': 5711,\n",
       " 'judging': 13999,\n",
       " 'my': 16617,\n",
       " 'mail': 15310,\n",
       " 'there': 24134,\n",
       " 'appear': 3471,\n",
       " 'quite': 19798,\n",
       " 'few': 10324,\n",
       " 'clear': 6040,\n",
       " 'mr': 16482,\n",
       " 'intends': 13368,\n",
       " 'continue': 6858,\n",
       " 'post': 18923,\n",
       " 'tangential': 23792,\n",
       " 'unrelated': 25243,\n",
       " 'articles': 3699,\n",
       " 'while': 26249,\n",
       " 'ingoring': 13173,\n",
       " 'themselves': 24105,\n",
       " 'between': 4514,\n",
       " 'last': 14510,\n",
       " 'two': 24883,\n",
       " 're': 20024,\n",
       " 'postings': 18937,\n",
       " 'noted': 17130,\n",
       " 'perhaps': 18272,\n",
       " 'dozen': 8717,\n",
       " 'more': 16376,\n",
       " 'posts': 18940,\n",
       " 'by': 5240,\n",
       " 'none': 17057,\n",
       " 'which': 26247,\n",
       " 'answered': 3349,\n",
       " 'single': 22192,\n",
       " 'challenge': 5708,\n",
       " 'unmistakable': 25209,\n",
       " 'me': 15700,\n",
       " 'hopes': 12386,\n",
       " 'questions': 19779,\n",
       " 'will': 26322,\n",
       " 'go': 11393,\n",
       " 'away': 4074,\n",
       " 'he': 11984,\n",
       " 'doing': 8633,\n",
       " 'level': 14731,\n",
       " 'best': 4496,\n",
       " 'change': 5725,\n",
       " 'subject': 23258,\n",
       " 'rather': 19958,\n",
       " 'common': 6383,\n",
       " 'net': 16849,\n",
       " 'theist': 24096,\n",
       " 'tactic': 23737,\n",
       " 'suggest': 23374,\n",
       " 'impress': 12896,\n",
       " 'upon': 25335,\n",
       " 'our': 17725,\n",
       " 'desire': 8023,\n",
       " 'answers': 3351,\n",
       " 'following': 10620,\n",
       " 'manner': 15432,\n",
       " 'ignore': 12710,\n",
       " 'any': 3392,\n",
       " 'future': 10979,\n",
       " 'do': 8586,\n",
       " 'address': 2669,\n",
       " 'until': 25280,\n",
       " 'them': 24100,\n",
       " 'explictly': 9936,\n",
       " 'announces': 3323,\n",
       " 'refuses': 20306,\n",
       " 'must': 16598,\n",
       " 'one': 17482,\n",
       " 'include': 12955,\n",
       " 'within': 26408,\n",
       " 'something': 22498,\n",
       " 'similar': 22145,\n",
       " 'please': 18688,\n",
       " 'answer': 3348,\n",
       " 'posed': 18892,\n",
       " 'really': 20077,\n",
       " 'looking': 15034,\n",
       " 'humiliate': 12517,\n",
       " 'here': 12119,\n",
       " 'want': 26031,\n",
       " 'some': 22487,\n",
       " 'honest': 12360,\n",
       " 'wouldn': 26522,\n",
       " 'think': 24172,\n",
       " 'honesty': 12362,\n",
       " 'too': 24440,\n",
       " 'much': 16515,\n",
       " 'ask': 3744,\n",
       " 'devout': 8127,\n",
       " 'christian': 5901,\n",
       " 'nevermind': 16877,\n",
       " 'rhetorical': 20850,\n",
       " 'question': 19773,\n",
       " 'aw': 4065,\n",
       " 'st': 22858,\n",
       " 'had': 11785,\n",
       " 'brief': 5003,\n",
       " 'blurb': 4759,\n",
       " 'on': 17474,\n",
       " 'manned': 15431,\n",
       " 'lunar': 15156,\n",
       " 'exploration': 9948,\n",
       " 'confernce': 6655,\n",
       " 'may': 15643,\n",
       " '7th': 1772,\n",
       " 'at': 3858,\n",
       " 'crystal': 7313,\n",
       " 'city': 5981,\n",
       " 'virginia': 25806,\n",
       " 'under': 25065,\n",
       " 'auspices': 3978,\n",
       " 'aiaa': 2928,\n",
       " 'how': 12441,\n",
       " 'attend': 3926,\n",
       " 'definitely': 7790,\n",
       " 'horrible': 12400,\n",
       " 'deaths': 7653,\n",
       " 'as': 3714,\n",
       " 'result': 20735,\n",
       " 'both': 4885,\n",
       " 'atheists': 3870,\n",
       " 'theists': 24098,\n",
       " 'sure': 23522,\n",
       " 'bobby': 4784,\n",
       " 'can': 5356,\n",
       " 'list': 14918,\n",
       " 'atheist': 3867,\n",
       " 'side': 22075,\n",
       " 'fails': 10105,\n",
       " 'recognize': 20154,\n",
       " 'equally': 9516,\n",
       " 'proficient': 19326,\n",
       " 'genocide': 11153,\n",
       " 'since': 22178,\n",
       " 'bit': 4655,\n",
       " 'weak': 26114,\n",
       " 'history': 12256,\n",
       " 'somone': 22506,\n",
       " 'give': 11309,\n",
       " 'wars': 26064,\n",
       " 'caused': 5546,\n",
       " 'led': 14639,\n",
       " 'hitler': 12264,\n",
       " 'claimed': 5995,\n",
       " 'example': 9780,\n",
       " 'complete': 6488,\n",
       " 'probably': 19271,\n",
       " 'effective': 9050,\n",
       " 'showing': 22034,\n",
       " 'absurd': 2457,\n",
       " 'statement': 22942,\n",
       " 'note': 17128,\n",
       " 'notice': 17135,\n",
       " 'always': 3139,\n",
       " 'sign': 22100,\n",
       " 'peace': 18183,\n",
       " 'should': 22017,\n",
       " 'own': 17828,\n",
       " 'advice': 2767,\n",
       " 'leave': 14625,\n",
       " 'beliefs': 4417,\n",
       " 'nanci': 16684,\n",
       " 'prado': 19003,\n",
       " 'old': 17435,\n",
       " 'pioneer': 18574,\n",
       " 'song': 22509,\n",
       " '1850': 481,\n",
       " 'goes': 11411,\n",
       " 'follows': 10622,\n",
       " 'cavern': 5558,\n",
       " 'canyon': 5391,\n",
       " 'excavating': 9782,\n",
       " 'mine': 16039,\n",
       " 'dwelt': 8889,\n",
       " 'miner': 16041,\n",
       " 'forty': 10733,\n",
       " 'niner': 16991,\n",
       " 'daughter': 7585,\n",
       " 'clementine': 6051,\n",
       " 'chorus': 5884,\n",
       " 'oh': 17420,\n",
       " 'darling': 7553,\n",
       " 'lost': 15071,\n",
       " 'gone': 11429,\n",
       " 'forever': 10683,\n",
       " 'also': 3106,\n",
       " 'explained': 9928,\n",
       " 'confirmed': 6671,\n",
       " 'reliable': 20419,\n",
       " 'data': 7568,\n",
       " 'source': 22547,\n",
       " 'an': 3219,\n",
       " 'acronym': 2596,\n",
       " 'combined': 6312,\n",
       " 'elemental': 9135,\n",
       " 'mapper': 15465,\n",
       " 'experiment': 9914,\n",
       " 'extended': 9984,\n",
       " 'non': 17053,\n",
       " 'terrestrial': 24010,\n",
       " 'intercept': 13393,\n",
       " 'near': 16768,\n",
       " 'earth': 8928,\n",
       " 'personally': 18342,\n",
       " 'made': 15251,\n",
       " 'up': 25306,\n",
       " 'fit': 10458,\n",
       " 'name': 16676,\n",
       " 'wales': 26007,\n",
       " 'larrison': 14498,\n",
       " 'space': 22567,\n",
       " 'technology': 23895,\n",
       " 'investor': 13553,\n",
       " 'acorn': 2586,\n",
       " 'replay': 20552,\n",
       " 'running': 21192,\n",
       " '25mhz': 839,\n",
       " 'arm': 3647,\n",
       " 'processor': 19292,\n",
       " '20': 629,\n",
       " 'slower': 22335,\n",
       " 'than': 24073,\n",
       " 'software': 22449,\n",
       " 'off': 17384,\n",
       " 'standard': 22894,\n",
       " 'cd': 5582,\n",
       " 'rom': 21030,\n",
       " '16': 390,\n",
       " 'colour': 6290,\n",
       " 'same': 21317,\n",
       " 'resolution': 20675,\n",
       " 'what': 26222,\n",
       " 'computer': 6555,\n",
       " 'has': 11936,\n",
       " 'support': 23494,\n",
       " 'real': 20061,\n",
       " 'time': 24321,\n",
       " 'dithering': 8524,\n",
       " '3d0': 1146,\n",
       " 'supposed': 23504,\n",
       " 'couple': 7101,\n",
       " 'dsps': 8809,\n",
       " 'being': 4406,\n",
       " 'housekeeping': 12435,\n",
       " '6xx': 1629,\n",
       " 'clock': 6094,\n",
       " 'around': 3663,\n",
       " 'mips': 16083,\n",
       " '18': 458,\n",
       " 'flat': 10494,\n",
       " 'out': 17728,\n",
       " 'depends': 7943,\n",
       " 'surrounding': 23547,\n",
       " 'system': 23705,\n",
       " 'whether': 26244,\n",
       " 'arm6x': 3648,\n",
       " 'arm6xx': 3649,\n",
       " 'latter': 14528,\n",
       " 'cache': 5273,\n",
       " 'essential': 9622,\n",
       " 'run': 21188,\n",
       " 'kind': 14224,\n",
       " 'speed': 22686,\n",
       " 'memory': 15794,\n",
       " 'll': 14957,\n",
       " 'stop': 23095,\n",
       " 'saying': 21420,\n",
       " 'things': 24171,\n",
       " 'cos': 7048,\n",
       " 'hopefully': 12385,\n",
       " 'working': 26485,\n",
       " 'graduation': 11508,\n",
       " 'mike': 15989,\n",
       " 'ps': 19529,\n",
       " 'don': 8657,\n",
       " 'pay': 18142,\n",
       " 'heed': 12047,\n",
       " 'reps': 20609,\n",
       " 'philips': 18429,\n",
       " 'doesn': 8621,\n",
       " 'beat': 4341,\n",
       " 'pants': 17963,\n",
       " '3di': 1148,\n",
       " 'then': 24106,\n",
       " 'eat': 8948,\n",
       " 'postscript': 18941,\n",
       " 'hiten': 12261,\n",
       " 'engineering': 9349,\n",
       " 'test': 24028,\n",
       " 'mission': 16156,\n",
       " 'spent': 22697,\n",
       " 'highly': 12200,\n",
       " 'eccentric': 8960,\n",
       " 'orbit': 17597,\n",
       " 'flybys': 10577,\n",
       " 'inserted': 13269,\n",
       " 'into': 13488,\n",
       " 'using': 25392,\n",
       " 'very': 25699,\n",
       " 'tricky': 24715,\n",
       " 'gravity': 11585,\n",
       " 'assist': 3786,\n",
       " 'maneuvering': 15397,\n",
       " 'meant': 15712,\n",
       " 'crash': 7164,\n",
       " 'moon': 16358,\n",
       " 'eventually': 9726,\n",
       " 'no': 17027,\n",
       " 'thing': 24170,\n",
       " 'stable': 22867,\n",
       " 'far': 10180,\n",
       " 'knows': 14302,\n",
       " 'believe': 4419,\n",
       " 'recall': 20119,\n",
       " 'hearing': 12015,\n",
       " 'recently': 20133,\n",
       " 'happen': 11875,\n",
       " 'interested': 13403,\n",
       " 'find': 10404,\n",
       " 'involved': 13569,\n",
       " 'processing': 19291,\n",
       " 'pairs': 17925,\n",
       " 'stereo': 23006,\n",
       " 'photographs': 18465,\n",
       " 'black': 4678,\n",
       " 'white': 26264,\n",
       " 'photos': 18481,\n",
       " 'obtain': 17318,\n",
       " 'surface': 23527,\n",
       " 'contours': 6869,\n",
       " 'prefer': 19085,\n",
       " 'sgi': 21871,\n",
       " 'hardware': 11904,\n",
       " 'type': 24893,\n",
       " 'image': 12769,\n",
       " 'email': 9187,\n",
       " 'comp': 6405,\n",
       " 'sys': 23702,\n",
       " 'graphics': 11552,\n",
       " 'responses': 20707,\n",
       " 'thanks': 24076,\n",
       " 'positional': 18897,\n",
       " 'uncertainties': 25026,\n",
       " '1993e': 589,\n",
       " 'assume': 3801,\n",
       " 'where': 26237,\n",
       " 'galileo': 11012,\n",
       " 'meters': 15892,\n",
       " 'without': 26409,\n",
       " 'hga': 12169,\n",
       " 'pretty': 19179,\n",
       " 'good': 11434,\n",
       " 'ideas': 12664,\n",
       " 'look': 15031,\n",
       " 'before': 4376,\n",
       " 'imaging': 12793,\n",
       " 'could': 7073,\n",
       " 'slew': 22304,\n",
       " 'less': 14714,\n",
       " 'light': 14832,\n",
       " 'delay': 7833,\n",
       " 'were': 26190,\n",
       " 'toutatis': 24502,\n",
       " 'didn': 8192,\n",
       " 'someone': 22494,\n",
       " 'get': 11239,\n",
       " 'lucky': 15139,\n",
       " 'guess': 11709,\n",
       " 'first': 10442,\n",
       " 'images': 12779,\n",
       " 'imagine': 12790,\n",
       " 'mostly': 16417,\n",
       " 'visual': 25841,\n",
       " 'affect': 2811,\n",
       " 'other': 17708,\n",
       " 'missions': 16159,\n",
       " 'lga': 14759,\n",
       " 'tight': 24304,\n",
       " 'allocation': 3070,\n",
       " 'bandwidth': 4200,\n",
       " 'premature': 19108,\n",
       " 'hope': 12383,\n",
       " 'throw': 24247,\n",
       " 'floor': 10544,\n",
       " 'program': 19338,\n",
       " 'tseng': 24793,\n",
       " 'et4000': 9646,\n",
       " 'nonstandard': 17074,\n",
       " '1024x768': 178,\n",
       " 'mode': 16238,\n",
       " 'switching': 23644,\n",
       " 'bios': 4630,\n",
       " 'changing': 5729,\n",
       " 'timing': 24334,\n",
       " 'details': 8056,\n",
       " '0x3d4': 143,\n",
       " 'registers': 20332,\n",
       " '0x00': 140,\n",
       " '0x1f': 142,\n",
       " 'select': 21715,\n",
       " '36': 1081,\n",
       " 'mhz': 15922,\n",
       " 'pixel': 18606,\n",
       " 'need': 16793,\n",
       " 'function': 10934,\n",
       " 'selects': 21722,\n",
       " '40': 1174,\n",
       " 'anybody': 3393,\n",
       " 'technical': 23882,\n",
       " 'info': 13140,\n",
       " 'am': 3143,\n",
       " 'trident': 24717,\n",
       " '8900': 1911,\n",
       " '9000': 1933,\n",
       " 'chipsets': 5859,\n",
       " 'reply': 20564,\n",
       " '20apr199312262902': 685,\n",
       " 'rigel': 20889,\n",
       " 'tamu': 23785,\n",
       " 'edu': 9027,\n",
       " 'lmp8913': 14963,\n",
       " 'preston': 19162,\n",
       " 'lisa': 14914,\n",
       " 'almost': 3087,\n",
       " 'sounds': 22545,\n",
       " '_nucleus_': 2260,\n",
       " 'coma': 6303,\n",
       " 'hundred': 12526,\n",
       " 'miles': 15996,\n",
       " 'well': 26183,\n",
       " 'rest': 20711,\n",
       " 'hello': 12085,\n",
       " 'add': 2656,\n",
       " 'voice': 25880,\n",
       " 'input': 13240,\n",
       " 'capability': 5396,\n",
       " 'user': 25385,\n",
       " 'interface': 13407,\n",
       " 'developing': 8103,\n",
       " 'hp730': 12450,\n",
       " 'unix': 25190,\n",
       " 'workstation': 26492,\n",
       " 'greatly': 11596,\n",
       " 'appreciate': 3508,\n",
       " 'care': 5437,\n",
       " 'offer': 17393,\n",
       " 'systems': 23709,\n",
       " 'easily': 8940,\n",
       " 'accessible': 2499,\n",
       " 'environment': 9449,\n",
       " 'names': 16682,\n",
       " 'adresses': 2728,\n",
       " 'applicable': 3489,\n",
       " 'vendors': 25627,\n",
       " 'experiences': 9913,\n",
       " 'specific': 22651,\n",
       " 'helpful': 12091,\n",
       " 'via': 25724,\n",
       " 'summary': 23413,\n",
       " 'sufficient': 23369,\n",
       " 'interest': 13402,\n",
       " 'ken': 14136,\n",
       " 'found': 10748,\n",
       " 'several': 21851,\n",
       " 'impressive': 12900,\n",
       " 'ibm': 12631,\n",
       " 'pc': 18158,\n",
       " 'avoid': 4057,\n",
       " 'hassle': 11940,\n",
       " 'purchasing': 19637,\n",
       " 'maintaining': 15334,\n",
       " 'separate': 21782,\n",
       " 'possible': 18920,\n",
       " 'hinckley': 12220,\n",
       " 'kph2q': 14344,\n",
       " 'university': 25187,\n",
       " 'neurosurgical': 16867,\n",
       " 'visualization': 25844,\n",
       " 'laboratory': 14414,\n",
       " 'reusable': 20780,\n",
       " 'tool': 24442,\n",
       " 'pointy': 18773,\n",
       " 'stick': 23037,\n",
       " 'better': 4513,\n",
       " 'closer': 6103,\n",
       " 'brains': 4941,\n",
       " 'size': 22235,\n",
       " 'armies': 3653,\n",
       " 'duration': 8867,\n",
       " 'numbers': 17220,\n",
       " 'casualties': 5512,\n",
       " 'absolute': 2438,\n",
       " 'percentage': 18250,\n",
       " 'geographical': 11199,\n",
       " 'area': 3608,\n",
       " 'countries': 7095,\n",
       " 'measures': 15722,\n",
       " 'case': 5491,\n",
       " 'relevant': 20414,\n",
       " 'statistic': 22954,\n",
       " 'number': 17217,\n",
       " 'combatants': 6307,\n",
       " 'total': 24482,\n",
       " 'troops': 24756,\n",
       " 'compared': 6418,\n",
       " 'among': 3194,\n",
       " 'civilian': 5984,\n",
       " 'population': 18866,\n",
       " 'affected': 2812,\n",
       " 'vietnam': 25759,\n",
       " 'korea': 14327,\n",
       " 'might': 15986,\n",
       " 'make': 15346,\n",
       " 'comparisons': 6423,\n",
       " 'western': 26205,\n",
       " 'news': 16904,\n",
       " 'general': 11118,\n",
       " 'particular': 18060,\n",
       " 'american': 3171,\n",
       " 'mass': 15566,\n",
       " 'media': 15739,\n",
       " 'cbs': 5567,\n",
       " 'nbc': 16750,\n",
       " 'abc': 2389,\n",
       " 'etc': 9648,\n",
       " 'tone': 24429,\n",
       " 'during': 8869,\n",
       " 'war': 26035,\n",
       " 'poor': 18853,\n",
       " 'iraqis': 13608,\n",
       " 'along': 3091,\n",
       " 'precisely': 19046,\n",
       " 'cruise': 7288,\n",
       " 'missile': 16153,\n",
       " 'blew': 4717,\n",
       " 'building': 5123,\n",
       " 'bits': 4666,\n",
       " 'agree': 2895,\n",
       " 'maybe': 15646,\n",
       " 'atomic': 3898,\n",
       " 'bomb': 4814,\n",
       " 'mistake': 16165,\n",
       " 'easy': 8947,\n",
       " 'enlightened': 9374,\n",
       " 'viewpoint': 25766,\n",
       " '90': 1931,\n",
       " 'right': 20890,\n",
       " 'back': 4118,\n",
       " 'germany': 11231,\n",
       " 'japan': 13785,\n",
       " 'squashed': 22815,\n",
       " 'million': 16015,\n",
       " 'british': 5023,\n",
       " 'already': 3103,\n",
       " 'died': 8196,\n",
       " 'hundreds': 12527,\n",
       " 'thousands': 24218,\n",
       " 'french': 10840,\n",
       " 'hundread': 12525,\n",
       " 'thousand': 24217,\n",
       " 'americans': 3172,\n",
       " 'millions': 16017,\n",
       " 'russians': 21209,\n",
       " 'mention': 15808,\n",
       " 'jews': 13853,\n",
       " 'poles': 18787,\n",
       " 'people': 18240,\n",
       " 'slavic': 22296,\n",
       " 'descent': 7993,\n",
       " 'german': 11228,\n",
       " 'concentration': 6582,\n",
       " 'camps': 5353,\n",
       " 'considered': 6749,\n",
       " 'fire': 10430,\n",
       " 'bombings': 4819,\n",
       " 'therefore': 24137,\n",
       " 'justified': 14047,\n",
       " 'bringing': 5016,\n",
       " 'quick': 19782,\n",
       " 'end': 9305,\n",
       " 'even': 9719,\n",
       " 'greater': 11594,\n",
       " 'allied': 3066,\n",
       " 'losses': 15067,\n",
       " 'regret': 20339,\n",
       " 'suffer': 23360,\n",
       " 'because': 4352,\n",
       " 'reason': 20090,\n",
       " 'depose': 7955,\n",
       " 'these': 24147,\n",
       " 'entrenched': 9433,\n",
       " 'political': 18802,\n",
       " 'rulers': 21176,\n",
       " 'operating': 17531,\n",
       " 'selfish': 21725,\n",
       " 'interests': 13406,\n",
       " 'mean': 15706,\n",
       " 'applies': 3494,\n",
       " 'allies': 3067,\n",
       " 'claim': 5993,\n",
       " 'effort': 9059,\n",
       " 'justify': 14048,\n",
       " 'misguided': 16122,\n",
       " 'foreign': 10672,\n",
       " 'policy': 18797,\n",
       " 'west': 26202,\n",
       " 'evident': 9747,\n",
       " 'especially': 9613,\n",
       " 'america': 3170,\n",
       " 'misjudged': 16132,\n",
       " 'hussein': 12551,\n",
       " 'drastically': 8738,\n",
       " 'once': 17477,\n",
       " 'invaded': 13518,\n",
       " 'kuwait': 14383,\n",
       " 'threatened': 24225,\n",
       " 'militarily': 16000,\n",
       " 'corner': 7001,\n",
       " 'significant': 22113,\n",
       " 'portion': 18880,\n",
       " 'world': 26494,\n",
       " 'oil': 17427,\n",
       " 'supply': 23492,\n",
       " 'stopped': 23096,\n",
       " 'prevented': 19185,\n",
       " 'judicious': 14003,\n",
       " 'concerted': 6596,\n",
       " 'part': 18041,\n",
       " 'still': 23048,\n",
       " 'responsible': 20710,\n",
       " 'decision': 7697,\n",
       " 'invade': 13517,\n",
       " 'did': 8190,\n",
       " 'strong': 23190,\n",
       " 'response': 20706,\n",
       " 'required': 20627,\n",
       " 'loving': 15101,\n",
       " 'allow': 3071,\n",
       " 'gobble': 11398,\n",
       " 'nearby': 16769,\n",
       " 'keep': 14118,\n",
       " 'slaughter': 22290,\n",
       " 'certain': 5659,\n",
       " 'peoples': 18241,\n",
       " 'dominion': 8654,\n",
       " 'yes': 26742,\n",
       " 'stopping': 23097,\n",
       " 'most': 16415,\n",
       " 'set': 21833,\n",
       " 'mind': 16031,\n",
       " 'military': 16002,\n",
       " 'conquest': 6726,\n",
       " 'mentioned': 15809,\n",
       " 'hadn': 11789,\n",
       " 'intervened': 13478,\n",
       " 'allowing': 3074,\n",
       " 'appeasement': 3478,\n",
       " 'lessons': 14719,\n",
       " 'learned': 14616,\n",
       " 'ww2': 26579,\n",
       " 'motivated': 16431,\n",
       " 'alliance': 3064,\n",
       " 'letting': 14729,\n",
       " 'austria': 3986,\n",
       " 'czechoslavkia': 7471,\n",
       " 'happening': 11877,\n",
       " 'eventual': 9724,\n",
       " 'gulf': 11731,\n",
       " 'protect': 19473,\n",
       " 'saudi': 21400,\n",
       " 'arabia': 3560,\n",
       " 'truly': 24774,\n",
       " 'unfortunate': 25124,\n",
       " 'followed': 10616,\n",
       " 'grandiose': 11531,\n",
       " 'quest': 19772,\n",
       " 'year': 26729,\n",
       " 'reich': 20352,\n",
       " 'consequences': 6738,\n",
       " 'stemmed': 22997,\n",
       " 'policemen': 18794,\n",
       " 'trial': 24696,\n",
       " 'rodney': 21008,\n",
       " 'king': 14233,\n",
       " 'law': 14550,\n",
       " 'deserved': 8010,\n",
       " 'jury': 14039,\n",
       " 'peers': 18201,\n",
       " 'officers': 17402,\n",
       " 'jurors': 14037,\n",
       " 'point': 18763,\n",
       " 'allegedly': 3049,\n",
       " 'racial': 19827,\n",
       " 'motivations': 16433,\n",
       " 'shallow': 21899,\n",
       " 'hard': 11889,\n",
       " 'argument': 3626,\n",
       " 'incredulity': 12998,\n",
       " 'gained': 11002,\n",
       " 'acceptance': 2491,\n",
       " 'revered': 20798,\n",
       " 'author': 3992,\n",
       " 'constructing': 6791,\n",
       " 'logical': 15011,\n",
       " 'expect': 9894,\n",
       " 'revision': 20813,\n",
       " 'soon': 22515,\n",
       " 'kidding': 14195,\n",
       " 'admit': 2710,\n",
       " 'wonder': 26449,\n",
       " 'neither': 16835,\n",
       " 'prosecution': 19461,\n",
       " 'nor': 17087,\n",
       " 'defense': 7776,\n",
       " 'cannot': 5380,\n",
       " 'conclude': 6601,\n",
       " 'either': 9099,\n",
       " 'way': 26105,\n",
       " 'due': 8834,\n",
       " 'silence': 22123,\n",
       " 'principals': 19225,\n",
       " 'ok': 17430,\n",
       " 'certainly': 5660,\n",
       " 'seemed': 21693,\n",
       " 'excessive': 9802,\n",
       " 'force': 10657,\n",
       " 'frankly': 10800,\n",
       " 'original': 17660,\n",
       " 'guilty': 11725,\n",
       " 'verdict': 25653,\n",
       " 'baffled': 4152,\n",
       " 'try': 24789,\n",
       " 'convict': 6935,\n",
       " 'charge': 5756,\n",
       " 'simple': 22153,\n",
       " 'assault': 3760,\n",
       " 'won': 26448,\n",
       " 'tried': 24718,\n",
       " 'conviction': 6938,\n",
       " 'aggravated': 2879,\n",
       " 'intent': 13376,\n",
       " 'inflict': 13131,\n",
       " 'serious': 21807,\n",
       " 'bodily': 4791,\n",
       " 'harm': 11908,\n",
       " 'commentators': 6353,\n",
       " 'akin': 2972,\n",
       " 'attempted': 3922,\n",
       " 'murder': 16565,\n",
       " 'california': 5313,\n",
       " 'based': 4262,\n",
       " 'asking': 3747,\n",
       " 'decided': 7690,\n",
       " 'wrong': 26556,\n",
       " 'inflicting': 13133,\n",
       " 'seeds': 21684,\n",
       " 'prosecutions': 19462,\n",
       " 'defeat': 7764,\n",
       " 'overconfidence': 17780,\n",
       " 'obtaining': 17321,\n",
       " 'went': 26189,\n",
       " 'extreme': 10018,\n",
       " 'facts': 10089,\n",
       " 'presented': 19139,\n",
       " 'true': 24766,\n",
       " 'feel': 10272,\n",
       " 'reasonable': 20091,\n",
       " 'mathew': 15603,\n",
       " 'quote': 19805,\n",
       " 'funny': 10961,\n",
       " 'monty': 16353,\n",
       " 'python': 19691,\n",
       " 'fan': 10164,\n",
       " 'vein': 25619,\n",
       " 'course': 7108,\n",
       " 'oversimplifying': 17810,\n",
       " 'moral': 16369,\n",
       " 'seem': 21692,\n",
       " 'contradictory': 6885,\n",
       " 'regards': 20320,\n",
       " 'stuff': 23226,\n",
       " 'deleted': 7838,\n",
       " 'seconds': 21652,\n",
       " 'minutes': 16081,\n",
       " 'hours': 12431,\n",
       " 'days': 7609,\n",
       " 'months': 16350,\n",
       " 'years': 26731,\n",
       " 'remember': 20460,\n",
       " 'fahrenheit': 10100,\n",
       " 'temperature': 23948,\n",
       " 'scale': 21433,\n",
       " 'centigrade': 5632,\n",
       " 'revisionists': 20815,\n",
       " 'tell': 23940,\n",
       " 'coldest': 6228,\n",
       " 'russian': 21208,\n",
       " 'winter': 26377,\n",
       " 'marked': 15503,\n",
       " 'thermometer': 24145,\n",
       " 'body': 4793,\n",
       " 'volunteer': 25904,\n",
       " 'turns': 24849,\n",
       " 'sick': 22069,\n",
       " 'win': 26341,\n",
       " 'em': 9185,\n",
       " 'marks': 15513,\n",
       " 'divided': 8538,\n",
       " 'hundredths': 12528,\n",
       " 'fwiw': 10986,\n",
       " 'doug': 8697,\n",
       " 'page': 17897,\n",
       " 'wasn': 26071,\n",
       " 'prominent': 19379,\n",
       " 'however': 12445,\n",
       " 'possibly': 18922,\n",
       " 'longer': 15026,\n",
       " 'display': 8454,\n",
       " 'nasm': 16700,\n",
       " 'museums': 16586,\n",
       " 'rotate': 21076,\n",
       " 'displays': 8458,\n",
       " 'occasionally': 17330,\n",
       " 'dm': 8570,\n",
       " 'fact': 10079,\n",
       " 'rumor': 21182,\n",
       " 'madalyn': 15247,\n",
       " 'murray': 16576,\n",
       " 'hare': 11906,\n",
       " 'eliminated': 9152,\n",
       " 'use': 25377,\n",
       " 'bible': 4545,\n",
       " 'reading': 20049,\n",
       " 'prayer': 19016,\n",
       " 'public': 19572,\n",
       " 'schools': 21502,\n",
       " '15': 351,\n",
       " 'ago': 2890,\n",
       " 'now': 17163,\n",
       " 'going': 11415,\n",
       " 'fcc': 10239,\n",
       " 'petition': 18383,\n",
       " 'gospel': 11450,\n",
       " 'airways': 2961,\n",
       " 'she': 21927,\n",
       " 'campaigning': 5346,\n",
       " 'remove': 20480,\n",
       " 'christmas': 5906,\n",
       " 'programs': 19351,\n",
       " 'songs': 22510,\n",
       " 'federal': 10261,\n",
       " 'communications': 6394,\n",
       " 'commission': 6369,\n",
       " '1919': 510,\n",
       " ...}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvect.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvec = CountVectorizer(stop_words='english', min_df=5) # add stop words, min_df only includes counts of words x number of times\n",
    "cvect.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26879"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cvect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit on a model\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and configure model\n",
    "\n",
    "clf = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_dtm = cvect.transform(data_train.data) \n",
    "X_test_dtm = cvect.transform(data_test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train_dtm, data_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7198817442719881"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test_dtm, data_test.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test out hashing and TF-IDF to improve score\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
       "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
       "                smooth_idf=True, stop_words='english', strip_accents=None,\n",
       "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.fit(data_train.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_T = tfidf.transform(data_train.data)\n",
    "X_test_T = tfidf.transform(data_test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgr = LogisticRegression()\n",
    "lgr.fit(X_train_T, data_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7479674796747967"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgr.score(X_test_T, data_test.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('tfidf', TfidfVectorizer()),('lgr', LogisticRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'tfidf__max_features': [10,100,1000,5000,10000],\n",
    "         'tfidf__min_df': [2,3,4,5,10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(pipe, param_grid=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('tfidf',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop...\n",
       "                                                           l1_ratio=None,\n",
       "                                                           max_iter=100,\n",
       "                                                           multi_class='warn',\n",
       "                                                           n_jobs=None,\n",
       "                                                           penalty='l2',\n",
       "                                                           random_state=None,\n",
       "                                                           solver='warn',\n",
       "                                                           tol=0.0001,\n",
       "                                                           verbose=0,\n",
       "                                                           warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'tfidf__max_features': [10, 100, 1000, 5000, 10000],\n",
       "                         'tfidf__min_df': [2, 3, 4, 5, 10]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(data_train.data, data_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7405764966740577"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.score(data_test.data, data_test.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Pipeline.get_params of Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=5000,\n",
       "                                 min_df=2, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('lgr',\n",
       "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='warn', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='warn', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_.get_params"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
